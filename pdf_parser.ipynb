{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unstructured.partition.auto import partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_contents(pdf_file):\n",
    "    elements = partition(filename=pdf_file)\n",
    "    text = ''\n",
    "    for element in elements:\n",
    "        try:\n",
    "            text = text + str(element) + '\\n'\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"2024\"\n",
    "out_folder = r\"Summary\"\n",
    "\n",
    "for file in os.listdir(folder):    \n",
    "    filename = os.path.join(folder, file)\n",
    "    print(file)\n",
    "    try:\n",
    "        text = extract_pdf_contents(filename)\n",
    "        out_file = os.path.join(out_folder, file.replace(\"pdf\", \"txt\"))\n",
    "        with open(out_file, \"w\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yoga = r\"translation.pdf\"\n",
    "elements = partition(filename=yoga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for element in elements:    \n",
    "    print(element)\n",
    "    index += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from lxml import etree\n",
    "import zipfile\n",
    "ooXMLns = {'w':'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "#Function to extract all the comments of document(Same as accepted answer)\n",
    "#Returns a dictionary with comment id as key and comment string as value\n",
    "def get_document_comments(docxFileName):\n",
    "    comments_dict={}\n",
    "    docxZip = zipfile.ZipFile(docxFileName)\n",
    "    commentsXML = docxZip.read('word/comments.xml')\n",
    "    et = etree.XML(commentsXML)\n",
    "    comments = et.xpath('//w:comment',namespaces=ooXMLns)\n",
    "    for c in comments:\n",
    "        comment=c.xpath('string(.)',namespaces=ooXMLns)\n",
    "        comment_id=c.xpath('@w:id',namespaces=ooXMLns)[0]\n",
    "        comments_dict[comment_id]=comment\n",
    "    return comments_dict\n",
    "#Function to fetch all the comments in a paragraph\n",
    "def paragraph_comments(paragraph,comments_dict):\n",
    "    comments=[]\n",
    "    for run in paragraph.runs:\n",
    "        comment_reference=run._r.xpath(\"./w:commentReference\")\n",
    "        if comment_reference:\n",
    "            comment_id=comment_reference[0].xpath('@w:id',namespaces=ooXMLns)[0]\n",
    "            comment=comments_dict[comment_id]\n",
    "            comments.append(comment)\n",
    "    return comments\n",
    "#Function to fetch all comments with their referenced paragraph\n",
    "#This will return list like this [{'Paragraph text': [comment 1,comment 2]}]\n",
    "def comments_with_reference_paragraph(docxFileName):\n",
    "    document = Document(docxFileName)\n",
    "    comments_dict=get_document_comments(docxFileName)\n",
    "    comments_with_their_reference_paragraph=[]\n",
    "    for paragraph in document.paragraphs:  \n",
    "        if comments_dict: \n",
    "            comments=paragraph_comments(paragraph,comments_dict)  \n",
    "            if comments:\n",
    "                comments_with_their_reference_paragraph.append({paragraph.text: comments})\n",
    "    return comments_with_their_reference_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"hello.pdf\"  #filepath for the input document\n",
    "print(comments_with_reference_paragraph(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    {\n",
    "        \"name\": \"Alice\",\n",
    "        \"like_to_spend_time_with\": [\"Bob\", \"Charlie\", \"David\"],\n",
    "        \"not_like_to_spend_time_with\": [\"Eve\", \"Frank\", \"Grace\"],\n",
    "        \"selected_by\": [\"Bob\", \"Charlie\"],\n",
    "        \"think_rejected_by\": [\"Eve\", \"Frank\"],\n",
    "    },\n",
    "    # Add more individuals' responses here...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (individuals)\n",
    "for person in responses:\n",
    "    G.add_node(person[\"name\"])\n",
    "\n",
    "# Add edges based on preferences\n",
    "for person in responses:\n",
    "    for liked_person in person[\"like_to_spend_time_with\"]:\n",
    "        G.add_edge(person[\"name\"], liked_person)\n",
    "\n",
    "# Visualize the graph\n",
    "pos = nx.spring_layout(G, seed=42)  # Layout algorithm\n",
    "nx.draw(G, pos, with_labels=True, node_size=800, font_size=10, font_color=\"black\")\n",
    "plt.title(\"Sociometric Graph: Preferences for Spending Free Time\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
